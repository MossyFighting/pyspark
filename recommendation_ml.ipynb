{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recommendation_ml.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmhShvWijdOb",
        "colab_type": "text"
      },
      "source": [
        "# Some Notes:\n",
        "- This recommendation is used the same with the file, recommendation_mllib, with the only difference is the ALS using the pyspark.ml, and input data is dataframe, instead of RDD for pyspark.mllib.\n",
        "- Another difference between two libraries is, predictions from ALS pyspark.ml returns some nulls, while in ALS pyspark.mllib does not due to the random split in RDD and dataframe difference. \n",
        "\n",
        "## 1. Setup google colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faKXXMb9jf-W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a242fb38-a930-4a35-9c23-b8255a120379"
      },
      "source": [
        "# setup for pyspark working on google colab\n",
        "'''\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cp '/content/gdrive/My Drive/pyspark/spark-2.4.5-bin-hadoop2.7.tgz' .\n",
        "\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# setup java hoem and spark home directory in google collab\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
        "\n",
        "# import some library pyspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark import SQLContext\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "# create spark context set-up\n",
        "conf = SparkConf().setAppName('sql_dataframe')\n",
        "sc = SparkContext.getOrCreate(conf = conf)\n",
        "sqlcontext = SQLContext(sc)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7meg8_BlCk_",
        "colab_type": "text"
      },
      "source": [
        "## 2. Reading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsUs2_VkR-Pv",
        "colab_type": "code",
        "outputId": "45e9e5ea-b81b-432a-dbcc-85662fa464b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# reading file ratings.csv in local drive into dataframe\n",
        "url = '/content/gdrive/My Drive/pyspark/recommendation/ratings.csv'\n",
        "df_ratings = sqlcontext.read.csv(url, inferSchema=True, header=True)\n",
        "df_ratings.printSchema()\n",
        "df_ratings = df_ratings.select(['userID','movieID','rating'])\n",
        "df_ratings.show(3)\n",
        "# summary about ratings.csv file\n",
        "# this summary to build the matrix model\n",
        "num_ratings = df_ratings.count()\n",
        "print('total number of ratings: ', num_ratings)\n",
        "print('total number of movies rated: ', df_ratings.select('movieId').distinct().count())\n",
        "print('total number of users rated: ', df_ratings.select('userId').distinct().count())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- userId: integer (nullable = true)\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            " |-- timestamp: integer (nullable = true)\n",
            "\n",
            "+------+-------+------+\n",
            "|userID|movieID|rating|\n",
            "+------+-------+------+\n",
            "|     1|      1|   4.0|\n",
            "|     1|      3|   4.0|\n",
            "|     1|      6|   4.0|\n",
            "+------+-------+------+\n",
            "only showing top 3 rows\n",
            "\n",
            "total number of ratings:  100836\n",
            "total number of movies rated:  9724\n",
            "total number of users rated:  610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLR-dHI6UweS",
        "colab_type": "code",
        "outputId": "78c41b53-e75d-4b32-e1c9-bf0cda4a4b30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "# reading file movies.csv in local drive into dataframe\n",
        "url = '/content/gdrive/My Drive/pyspark/recommendation/movies.csv'\n",
        "df_movies = sqlcontext.read.csv(url, inferSchema=True, header=True)\n",
        "df_movies.printSchema()\n",
        "df_movies.show(3)\n",
        "# reading file tags.csv in local drive into dataframe\n",
        "url = '/content/gdrive/My Drive/pyspark/recommendation/tags.csv'\n",
        "df_tags = sqlcontext.read.csv(url, inferSchema=True, header=True)\n",
        "df_tags.printSchema()\n",
        "df_tags.show(3)\n",
        "# reading file links.csv in the local drive into dataframe\n",
        "url = '/content/gdrive/My Drive/pyspark/recommendation/links.csv'\n",
        "df_links = sqlcontext.read.csv(url, inferSchema=True, header=True)\n",
        "df_links.printSchema()\n",
        "df_links.show(3)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- genres: string (nullable = true)\n",
            "\n",
            "+-------+--------------------+--------------------+\n",
            "|movieId|               title|              genres|\n",
            "+-------+--------------------+--------------------+\n",
            "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
            "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
            "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
            "+-------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n",
            "root\n",
            " |-- userId: integer (nullable = true)\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- tag: string (nullable = true)\n",
            " |-- timestamp: integer (nullable = true)\n",
            "\n",
            "+------+-------+---------------+----------+\n",
            "|userId|movieId|            tag| timestamp|\n",
            "+------+-------+---------------+----------+\n",
            "|     2|  60756|          funny|1445714994|\n",
            "|     2|  60756|Highly quotable|1445714996|\n",
            "|     2|  60756|   will ferrell|1445714992|\n",
            "+------+-------+---------------+----------+\n",
            "only showing top 3 rows\n",
            "\n",
            "root\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- imdbId: integer (nullable = true)\n",
            " |-- tmdbId: integer (nullable = true)\n",
            "\n",
            "+-------+------+------+\n",
            "|movieId|imdbId|tmdbId|\n",
            "+-------+------+------+\n",
            "|      1|114709|   862|\n",
            "|      2|113497|  8844|\n",
            "|      3|113228| 15602|\n",
            "+-------+------+------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9kOChzYlH70",
        "colab_type": "text"
      },
      "source": [
        "## 3. Making predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACQR216Ga5VS",
        "colab_type": "code",
        "outputId": "688a68a8-6cf9-4c72-f9fe-badaf2f0cf67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# making prediction on the ratings dataframe\n",
        "data_train, data_test = df_ratings.randomSplit([0.8, 0.2], seed = 12345)\n",
        "num_train, num_test = data_train.count(), data_test.count()\n",
        "print('number of data length: ', df_ratings.count())\n",
        "print('number of training data: ', num_train)\n",
        "print('number of test data: ', num_test)\n",
        "print('num_train + num_test = ', num_train + num_test)\n",
        "# change column name for data_train to fit ALS() API\n",
        "data_train = (data_train.withColumnRenamed('userId', 'user')\n",
        "                        .withColumnRenamed('movieId', 'item'))\n",
        "\n",
        "# process data_test by dropping last column\n",
        "# and rename to column to fit with ALS() API\n",
        "data_test_removed = data_test.select(['userId','movieId'])\n",
        "data_test_removed = (data_test_removed.withColumnRenamed('userId', 'user')\n",
        "                                      .withColumnRenamed('movieId', 'item'))\n",
        "data_test_removed.show(3) \n",
        "# train model ALS (alternative least square).\n",
        "# split large sparse matrix into product of \n",
        "# two matrices with lower rank.\n",
        "from pyspark.ml.recommendation import ALS\n",
        "model_als = ALS(rank = 20, maxIter = 20, coldStartStrategy = \"drop\")\n",
        "model_als_fit = model_als.fit(data_train)\n",
        "predicted_test = model_als_fit.transform(data_test_removed)\n",
        "print('total line of predicted_test (ALS model automatically removed those predictions is null/nan): ', predicted_test.count())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of data length:  100836\n",
            "number of training data:  80487\n",
            "number of test data:  20349\n",
            "num_train + num_test =  100836\n",
            "+----+----+\n",
            "|user|item|\n",
            "+----+----+\n",
            "|   1|  50|\n",
            "|   1| 110|\n",
            "|   1| 151|\n",
            "+----+----+\n",
            "only showing top 3 rows\n",
            "\n",
            "total line of predicted_test (ALS model automatically removed those predictions is null/nan):  19536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuNWJxG8vrDV",
        "colab_type": "code",
        "outputId": "75fc3016-866d-4d69-93cd-80707812f61e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "# join predicted_test with data_test (including actual test)\n",
        "data_test_actual_predicted = (data_test.join(predicted_test\n",
        "                                      , (data_test.userID == predicted_test.user) \n",
        "                                      & (data_test.movieID == predicted_test.item) \n",
        "                                      , how = 'left' ))\n",
        "\n",
        "# data after join is not following the order of original dataframe\n",
        "data_test_actual_predicted.show(3)\n",
        "\n",
        "# we sort out the result of join in order user, item \n",
        "# to make result dataframe look like before\n",
        "data_test.show(3)\n",
        "data_test_actual_predicted = (data_test_actual_predicted\n",
        "                                                        .sort(['userID','movieID'], ascending = True)\n",
        "                                                        .drop('user')\n",
        "                                                        .drop('item'))\n",
        "data_test_actual_predicted.show(3)\n",
        "                                                        "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+------+----+----+----------+\n",
            "|userID|movieID|rating|user|item|prediction|\n",
            "+------+-------+------+----+----+----------+\n",
            "|     1|   1208|   4.0|   1|1208| 4.9291854|\n",
            "|     9|   5481|   5.0|   9|5481| 2.6461997|\n",
            "|    42|    434|   4.0|  42| 434| 2.9978712|\n",
            "+------+-------+------+----+----+----------+\n",
            "only showing top 3 rows\n",
            "\n",
            "+------+-------+------+\n",
            "|userID|movieID|rating|\n",
            "+------+-------+------+\n",
            "|     1|     50|   5.0|\n",
            "|     1|    110|   4.0|\n",
            "|     1|    151|   5.0|\n",
            "+------+-------+------+\n",
            "only showing top 3 rows\n",
            "\n",
            "+------+-------+------+----------+\n",
            "|userID|movieID|rating|prediction|\n",
            "+------+-------+------+----------+\n",
            "|     1|     50|   5.0| 4.7725115|\n",
            "|     1|    110|   4.0| 4.6414976|\n",
            "|     1|    151|   5.0| 3.6864564|\n",
            "+------+-------+------+----------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oz2SgkKlM2c",
        "colab_type": "text"
      },
      "source": [
        "## 4. Some evaluations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JPzSyx6xya7",
        "colab_type": "code",
        "outputId": "ce46f760-3ed5-48ac-f8a3-5cf3b1d130a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compute the false positive for those predictions\n",
        "# that are greater than the two limits 0 and 5 in \n",
        "# the rating scale.\n",
        "number_fasle_positive = data_test_actual_predicted.filter(data_test_actual_predicted.prediction.between(0,5))\n",
        "print('number of false positive and null or nan in the recommendation: ', data_test_actual_predicted.count() - number_fasle_positive.count())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of false positive and null or nan in the recommendation:  852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM9t89Op589H",
        "colab_type": "code",
        "outputId": "c0b56471-4030-492b-b2b2-f3a9dfa517d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "# Evaluate the model using root mean square error\n",
        "from pyspark.sql.functions import when, count, isnan, isnull\n",
        "\n",
        "# before evaluate, we check how many null/nan existing in the predictions\n",
        "data_test_actual_predicted.show(3)\n",
        "data_test_actual_predicted.printSchema()\n",
        "data_test_actual_predicted.select([count(when(isnan(c), 1)).alias(c) for c in data_test_actual_predicted.columns]).show()\n",
        "data_test_actual_predicted.select([count(when(isnull(c), 1)).alias(c) for c in data_test_actual_predicted.columns]).show() \n",
        "\n",
        "# remove rows with null/nan\n",
        "df_evaluate = data_test_actual_predicted.dropna()\n",
        "num_nonna = df_evaluate.count()\n",
        "print('number of lines without null: ', num_nonna)\n",
        "\n",
        "# Root Mean Square Error\n",
        "import math\n",
        "df_evaluate = df_evaluate.withColumn('rmse', ((data_test_actual_predicted.rating \n",
        "                                              -data_test_actual_predicted.prediction)**2))\n",
        "df_evaluate.show(3)\n",
        "val = df_evaluate.agg({'rmse': 'sum'}).collect()[0][0]\n",
        "rmse = math.sqrt(val/num_nonna)\n",
        "print('root mean square error of recommendation system is: ', rmse)\n",
        "\n",
        "# Mean Absoluted Error\n",
        "from pyspark.sql.functions import abs\n",
        "df_evaluate = df_evaluate.withColumn('mae', abs(data_test_actual_predicted.rating \n",
        "                                               -data_test_actual_predicted.prediction))\n",
        "\n",
        "df_evaluate.agg({'mae': 'sum'}).collect()[0][0]\n",
        "mae = val/num_nonna\n",
        "print('mean absolute error of recommendation system is: ', mae)\n",
        "df_evaluate.printSchema()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+------+----------+\n",
            "|userID|movieID|rating|prediction|\n",
            "+------+-------+------+----------+\n",
            "|     1|     50|   5.0|  4.599513|\n",
            "|     1|    110|   4.0| 4.6269245|\n",
            "|     1|    151|   5.0| 3.5044563|\n",
            "+------+-------+------+----------+\n",
            "only showing top 3 rows\n",
            "\n",
            "root\n",
            " |-- userID: integer (nullable = true)\n",
            " |-- movieID: integer (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            " |-- prediction: float (nullable = true)\n",
            "\n",
            "+------+-------+------+----------+\n",
            "|userID|movieID|rating|prediction|\n",
            "+------+-------+------+----------+\n",
            "|     0|      0|     0|         0|\n",
            "+------+-------+------+----------+\n",
            "\n",
            "+------+-------+------+----------+\n",
            "|userID|movieID|rating|prediction|\n",
            "+------+-------+------+----------+\n",
            "|     0|      0|     0|       813|\n",
            "+------+-------+------+----------+\n",
            "\n",
            "number of lines without null:  19536\n",
            "+------+-------+------+----------+-------------------+\n",
            "|userID|movieID|rating|prediction|               rmse|\n",
            "+------+-------+------+----------+-------------------+\n",
            "|     1|     50|   5.0|  4.599513|0.16038979400127573|\n",
            "|     1|    110|   4.0| 4.6269245|0.39303434722023667|\n",
            "|     1|    151|   5.0| 3.5044563|  2.236651013460289|\n",
            "+------+-------+------+----------+-------------------+\n",
            "only showing top 3 rows\n",
            "\n",
            "root mean square error of recommendation system is:  0.882397831031115\n",
            "mean absolute error of recommendation system is:  0.7786259322084162\n",
            "root\n",
            " |-- userID: integer (nullable = true)\n",
            " |-- movieID: integer (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            " |-- prediction: float (nullable = true)\n",
            " |-- rmse: double (nullable = true)\n",
            " |-- mae: double (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnuRPsYpX-sx",
        "colab_type": "code",
        "outputId": "b0369d32-748e-4faf-f534-9d3604214c88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# the built-in function 'RegressionEvaluator' is an \n",
        "# alternative to computing rmse \n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating', predictionCol='prediction')\n",
        "rmse = evaluator.evaluate(df_evaluate)\n",
        "print(\"Root-mean-square error: \",rmse)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Root-mean-square error:  0.8823978310311149\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}