{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recommendation_mllib_rdd.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPjPvh2DF7Go",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "In this small task of recommendation, the dataset is obtained from [dataset for recommendation](https://grouplens.org/datasets/movielens/).\n",
        "\n",
        "Recommendation is useful to help both provider and consumer to maximize provider's profits or user's knowledge/exploration, and this technique is very popular in big data processing with huge dataset.\n",
        "\n",
        "In this small task, we will go through following steps based on the idea of matrix factorization [here](https://dl.acm.org/doi/10.1109/MC.2009.263) and collaborative filtering [here](https://ieeexplore.ieee.org/document/4781121).\n",
        "- load the dataset and processing \n",
        "- exploration dataset to find some intuitations about the dataset\n",
        "- train Alternative Least Square model for recommendation\n",
        "- make recommendation for the most active user\n",
        "- evaluation the trained model on test dataset based on metrics rmse, mae. (root mean square error and mean absolute error).\n",
        "- some conclusions.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6iNi0qTSSAR",
        "colab_type": "text"
      },
      "source": [
        "# 1. Setup colab to work with pyspark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DlfwHXtF5Yo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2536261-d9cc-4bdb-ad80-e9a6dbf6603e"
      },
      "source": [
        "# setup for pyspark working on google colab\n",
        "'''\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cp '/content/gdrive/My Drive/pyspark/spark-2.4.5-bin-hadoop2.7.tgz' .\n",
        "\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# setup java home and spark home directory in google collab\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
        "\n",
        "# import some library pyspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark import SQLContext\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "# create spark context set-up\n",
        "conf = SparkConf().setAppName('sql_dataframe')\n",
        "sc = SparkContext.getOrCreate(conf = conf)\n",
        "sqlcontext = SQLContext(sc)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Iv_VK_MGDAN",
        "colab_type": "text"
      },
      "source": [
        "# 2. Reading data ratings from local file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC8fiSYLzS8h",
        "colab_type": "code",
        "outputId": "fa1f5bf1-d6f7-4a43-808c-0e2f79d336c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# reading file in local system\n",
        "url = '/content/gdrive/My Drive/pyspark/recommendation/ratings.csv'\n",
        "\n",
        "# take first header \n",
        "str_header = sc.textFile(url).first()\n",
        "\n",
        "# read ratings and remove header\n",
        "rdd_ratings = (sc.textFile(url).map(lambda x: x.split(','))\n",
        "                               .filter(lambda x: x != str_header.split(','))                             \n",
        "                               .map(lambda x: (int(x[0]), int(x[1]), float(x[2])))\n",
        "                               )\n",
        "\n",
        "# show the first two lines of rdd ratings\n",
        "print('First two lines of rdd_ratings: ', rdd_ratings.take(2))\n",
        "\n",
        "# convert to rdd\n",
        "df_ratings = rdd_ratings.toDF(['userID', 'movieID', 'rating'])\n",
        "df_ratings.show(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First two lines of rdd_ratings:  [(1, 1, 4.0), (1, 3, 4.0)]\n",
            "+------+-------+------+\n",
            "|userID|movieID|rating|\n",
            "+------+-------+------+\n",
            "|     1|      1|   4.0|\n",
            "|     1|      3|   4.0|\n",
            "|     1|      6|   4.0|\n",
            "|     1|     47|   5.0|\n",
            "|     1|     50|   5.0|\n",
            "+------+-------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IFRpTRc-xae",
        "colab_type": "text"
      },
      "source": [
        "### **Alternative way to remove header with rdd**\n",
        "- *create rdd header*, *create rdd with full content*, then, *full - header*\n",
        "1. rdd_head = sc.parallelize([sc.textFile(url).first()])\n",
        "2. rdd_alternative = sc.textFile(url)\n",
        "3. rdd_alternative.subtract(rdd_header).take(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YN6Y9Wg1IGiy",
        "colab_type": "text"
      },
      "source": [
        "# 3. Exploration the data ratings, movies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olybdRe0IXtn",
        "colab_type": "code",
        "outputId": "6c49953e-c6f6-4765-8fe1-fc848e7dec44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "## reading movies \n",
        "# reading file in local system\n",
        "url = '/content/gdrive/My Drive/pyspark/recommendation/movies.csv'\n",
        "\n",
        "# take first header \n",
        "str_header = sc.textFile(url).first()\n",
        "\n",
        "# read ratings and remove header\n",
        "rdd_movies = (sc.textFile(url).map(lambda x: x.split(','))\n",
        "                               .filter(lambda x: x != str_header.split(','))                              \n",
        "                               .map(lambda x: (int(x[0]), str(x[1]), str(x[2]))))\n",
        "## convert rdd to dataframe\n",
        "df_movies = rdd_movies.toDF(['movieID', 'title', 'genres'])\n",
        "df_movies.show(3)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+--------------------+\n",
            "|movieID|               title|              genres|\n",
            "+-------+--------------------+--------------------+\n",
            "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
            "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
            "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
            "+-------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCj8rYG4Plxx",
        "colab_type": "code",
        "outputId": "4ab67f95-b9bf-47fa-87b7-2e95ba3c65e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# assign df_ratings and df_movies to Tempview to use sql querries\n",
        "df_ratings.registerTempTable('ratings')\n",
        "df_movies.registerTempTable('movies')\n",
        "\n",
        "# get lowest and highest ratings for each movie\n",
        "# and the total number of users rated for that movie\n",
        "df_summary = sqlcontext.sql(''' \n",
        "    SELECT  M.title,\n",
        "            N.movieID,\n",
        "            N.minrate,\n",
        "            N.maxrate,\n",
        "            N.numuser\n",
        "    FROM  (SELECT ratings.movieID,\n",
        "                  min(ratings.rating) AS minrate, \n",
        "                  max(ratings.rating) AS maxrate, \n",
        "                  count(DISTINCT ratings.userID) AS numuser \n",
        "           FROM ratings \n",
        "           GROUP BY ratings.movieID) N\n",
        "    JOIN  movies M\n",
        "    ON  N.movieID = M.movieID\n",
        "    ORDER BY N.numuser DESC\n",
        "                       \n",
        "''')\n",
        "df_summary.show(10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-------+-------+-------+-------+\n",
            "|               title|movieID|minrate|maxrate|numuser|\n",
            "+--------------------+-------+-------+-------+-------+\n",
            "| Forrest Gump (1994)|    356|    0.5|    5.0|    329|\n",
            "|\"Shawshank Redemp...|    318|    1.0|    5.0|    317|\n",
            "| Pulp Fiction (1994)|    296|    0.5|    5.0|    307|\n",
            "|\"Silence of the L...|    593|    0.5|    5.0|    279|\n",
            "|             \"Matrix|   2571|    0.5|    5.0|    278|\n",
            "|Star Wars: Episod...|    260|    0.5|    5.0|    251|\n",
            "|Jurassic Park (1993)|    480|    0.5|    5.0|    238|\n",
            "|   Braveheart (1995)|    110|    0.5|    5.0|    237|\n",
            "|Terminator 2: Jud...|    589|    0.5|    5.0|    224|\n",
            "|Schindler's List ...|    527|    0.5|    5.0|    220|\n",
            "+--------------------+-------+-------+-------+-------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_x3daI__ozp",
        "colab_type": "code",
        "outputId": "6b75ce5b-8ed8-40d3-bbe5-b7993e68c726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# Show top of user who rated most frequent\n",
        "df_active_user = sqlcontext.sql('''\n",
        "    SELECT r.userID, \n",
        "           count(*) AS numrate\n",
        "    FROM ratings r\n",
        "    GROUP BY r.userID\n",
        "    ORDER BY numrate \n",
        "    DESC  \n",
        "''')\n",
        "\n",
        "df_active_user.show(10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+\n",
            "|userID|numrate|\n",
            "+------+-------+\n",
            "|   414|   2698|\n",
            "|   599|   2478|\n",
            "|   474|   2108|\n",
            "|   448|   1864|\n",
            "|   274|   1346|\n",
            "|   610|   1302|\n",
            "|    68|   1260|\n",
            "|   380|   1218|\n",
            "|   606|   1115|\n",
            "|   288|   1055|\n",
            "+------+-------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5apTKYCCcGS",
        "colab_type": "code",
        "outputId": "809f0193-0f38-4478-b1c3-1d99b910a6c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# It is clearly that the userID = 414 has the highest\n",
        "# number of rates  with 2698 times. Now, we can filter \n",
        "# to see how many times he rated greater than 4.5 stars\n",
        "df_userID_414 =  sqlcontext.sql(''' \n",
        "    SELECT m.title,\n",
        "           r.movieID,\n",
        "           r.rating\n",
        "    FROM ratings r\n",
        "    JOIN movies m\n",
        "    ON r.movieID = m.movieID\n",
        "    WHERE (r.userID = 414 AND r.rating >= 4.5)\n",
        "''')\n",
        "\n",
        "df_userID_414.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-------+------+\n",
            "|               title|movieID|rating|\n",
            "+--------------------+-------+------+\n",
            "|Up in the Air (2009)|  72011|   4.5|\n",
            "| Blade Runner (1982)|    541|   5.0|\n",
            "|Cyrano de Bergera...|   1277|   5.0|\n",
            "|LÃ©on: The Profess...|    293|   5.0|\n",
            "|    Secretary (2002)|   5617|   5.0|\n",
            "| Spider-Man 2 (2004)|   8636|   4.5|\n",
            "|Wallace & Gromit:...|    720|   5.0|\n",
            "|        \"Dirty Dozen|   2944|   5.0|\n",
            "|   Robin Hood (1973)|   3034|   5.0|\n",
            "|Kubo and the Two ...| 162578|   4.5|\n",
            "| Pulp Fiction (1994)|    296|   5.0|\n",
            "|          Ran (1985)|   1217|   5.0|\n",
            "|Sleepy Hollow (1999)|   3081|   5.0|\n",
            "|Scent of a Woman ...|   3252|   5.0|\n",
            "|Hope and Glory (1...|   4117|   5.0|\n",
            "|Million Dollar Ba...|  30707|   4.5|\n",
            "|To Sir with Love ...|   3296|   5.0|\n",
            "|Midnight in the G...|   1711|   5.0|\n",
            "| American Pie (1999)|   2706|   5.0|\n",
            "|       WALLÂ·E (2008)|  60069|   4.5|\n",
            "+--------------------+-------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtWPgPnLGlgn",
        "colab_type": "text"
      },
      "source": [
        "# 4. train the model using ALS "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v27uDyqb-77o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4ac6b16c-ae10-4dca-9e0a-8f6ebf56d342"
      },
      "source": [
        "# import the model ALS to train\n",
        "from pyspark.mllib.recommendation import ALS, Rating, MatrixFactorizationModel\n",
        "\n",
        "# using Rating function to prepare input for ALS() model\n",
        "rdd_ratings_Rating = rdd_ratings.map(lambda x: Rating(int(x[0]), int(x[1]), float(x[2])))\n",
        "print('two first lines after applying Rating: ', rdd_ratings_Rating.take(2))\n",
        "\n",
        "# split data into train_data and test_data\n",
        "rdd_train, rdd_test = rdd_ratings_Rating.randomSplit([0.8, 0.2], seed = 12345)\n",
        "print('number of train data: ', rdd_train.count())\n",
        "print('number of test data: ', rdd_test.count())\n",
        "\n",
        "# train ALS() \n",
        "number_of_latent_features = 20\n",
        "number_of_iterations = 20 \n",
        "model = ALS.train(rdd_ratings_Rating, number_of_latent_features, number_of_iterations)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "two first lines after applying Rating:  [Rating(user=1, product=1, rating=4.0), Rating(user=1, product=3, rating=4.0)]\n",
            "number of train data:  80828\n",
            "number of test data:  20008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okeZ-BHYKLmK",
        "colab_type": "text"
      },
      "source": [
        "# 5. Make recommendations for active userID "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqJtTpmJKTPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "0eaf4f23-cde7-4ef7-db12-fa0d392f5ab0"
      },
      "source": [
        "# use trained model  to return recommend\n",
        "toprecommend = model.recommendProducts(414, 10)\n",
        "df_recommend = sqlcontext.createDataFrame(toprecommend)\n",
        "df_recommend.show()\n",
        "\n",
        "# show the recommended movies\n",
        "df_join = df_recommend.join(df_movies, df_recommend.product == df_movies.movieID, how='left')\n",
        "df_join.drop('movieID', 'rating').show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+-------+------------------+\n",
            "|user|product|            rating|\n",
            "+----+-------+------------------+\n",
            "| 414|   3468|  5.78499878169281|\n",
            "| 414|   8228| 5.565813532052579|\n",
            "| 414|   1284| 5.506483477088946|\n",
            "| 414|   3421| 5.468809189201311|\n",
            "| 414|    954|5.4200399170853615|\n",
            "| 414|   2997| 5.344885289603891|\n",
            "| 414|    720|5.2965448293393065|\n",
            "| 414|    912| 5.270203470393725|\n",
            "| 414|   1249| 5.257831454528875|\n",
            "| 414|   1090| 5.244817220249215|\n",
            "+----+-------+------------------+\n",
            "\n",
            "+----+-------+--------------------+--------------------+\n",
            "|user|product|               title|              genres|\n",
            "+----+-------+--------------------+--------------------+\n",
            "| 414|    720|Wallace & Gromit:...|Adventure|Animati...|\n",
            "| 414|   8228|     \"Maltese Falcon| The (a.k.a. Dang...|\n",
            "| 414|   3468|            \"Hustler|         The (1961)\"|\n",
            "| 414|    912|   Casablanca (1942)|       Drama|Romance|\n",
            "| 414|   1284|          \"Big Sleep|         The (1946)\"|\n",
            "| 414|   3421| Animal House (1978)|              Comedy|\n",
            "| 414|   1090|      Platoon (1986)|           Drama|War|\n",
            "| 414|    954|Mr. Smith Goes to...|               Drama|\n",
            "| 414|   2997|Being John Malkov...|Comedy|Drama|Fantasy|\n",
            "| 414|   1249|       \"Femme Nikita| La (Nikita) (1990)\"|\n",
            "+----+-------+--------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUZpx4-4Gs-8",
        "colab_type": "text"
      },
      "source": [
        "# 6. Evaluation the predictions and the actual ratings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy6j9XMv6piT",
        "colab_type": "code",
        "outputId": "53870335-8602-46bd-c57d-04c63f0b93ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# prepare the test data\n",
        "rdd_test_remove_prediction = rdd_test.map(lambda x: (int(x[0]), int(x[1])))\n",
        "print('two first line of rdd_test after removing prediction: ', rdd_test_remove_prediction.take(2))\n",
        "\n",
        "# prediction on redd_test_remove_prediction using model after fit \n",
        "rdd_prediction_test = model.predictAll(rdd_test_remove_prediction).map(lambda x: ((x[0], x[1]), x[2]))\n",
        "print('two fisrt line of predictions using model: ', rdd_prediction_test.take(2))\n",
        "print('number of predictions has valid label: ', rdd_prediction_test.count())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "two first line of rdd_test after removing prediction:  [(1, 1), (1, 231)]\n",
            "two fisrt line of predictions using model:  [((590, 1084), 4.252041544191991), ((32, 1084), 4.199594019243957)]\n",
            "number of predictions has valid label:  20008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unJhRRbbGvac",
        "colab_type": "code",
        "outputId": "28016547-f84e-4300-98fe-36fe0142b92c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# evaluation\n",
        "# join two rdds (rdd_test and rdd_prediction_test)\n",
        "import math\n",
        "rdd_actualvspredicted = rdd_test.map(lambda x: ((x[0], x[1]), x[2])).join(rdd_prediction_test)\n",
        "print('first two lines of joined rdd: ', rdd_actualvspredicted.first())\n",
        "print('number of lines after join: ', rdd_actualvspredicted.count()) \n",
        "\n",
        "# evaluate predictions using (rmse)\n",
        "mse = (rdd_actualvspredicted.map(lambda x: (x[1][0] - x[1][1])**2)\n",
        "                            .mean())\n",
        "print('root mean square error: ', math.sqrt(mse))\n",
        "\n",
        "# evaluate mean absolute error (mae)\n",
        "mae = (rdd_actualvspredicted.map(lambda x: abs(x[1][0] - x[1][1]))\n",
        "                            .mean())\n",
        "print('mean absolute square error: ', mae) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first two lines of joined rdd:  ((1, 1), (4.0, 4.67654777615138))\n",
            "number of lines after join:  20008\n",
            "root mean square error:  0.3409566405717262\n",
            "mean absolute square error:  0.22442322712402069\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gy7CQgqGyZ4",
        "colab_type": "text"
      },
      "source": [
        "# 7. Check whether any null data in rdd predictions  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghYWZ_5MqFn1",
        "colab_type": "code",
        "outputId": "410a9780-8a7b-46f1-fc81-24fe505bb9bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# check null in the prediction\n",
        "# first take all predictions in scale range [0-5]\n",
        "rdd_subtract = rdd_prediction_test.filter(lambda x: (x[1] >= 0 and x[1] <= 5))\n",
        "# subtract the scale range [0-5] to see the ouliers \n",
        "# whether it contains null/nan or not \n",
        "len_outlier = len(rdd_prediction_test.subtract(rdd_subtract).collect())\n",
        "len_range_0_5 = rdd_subtract.count()\n",
        "print('total test is: 20008?', len_outlier+len_range_0_5)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total test is: 20008? 20008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cywtgVLoR0Vu",
        "colab_type": "text"
      },
      "source": [
        "# 8. Conclusion\n",
        "As we can see that the evaluation show that the root mean square error and the mean absolute error, both around 0.33, are quite small, and show the effectiveness of the method recommendation."
      ]
    }
  ]
}